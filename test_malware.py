#!/usr/bin/env python3
"""
Test malware detection model on VMShare binary files
"""
import os
import joblib
import numpy as np
from sklearn.preprocessing import StandardScaler
import pandas as pd
import hashlib

# Load trained model and scaler
model_path = os.path.expanduser('~/malware_detection/model_rf.pkl')
scaler_path = os.path.expanduser('~/malware_detection/scaler.pkl')

print(f"[*] Loading model from: {model_path}")
model = joblib.load(model_path)
print(f"[âœ“] Model loaded")

print(f"[*] Loading scaler from: {scaler_path}")
scaler = joblib.load(scaler_path)
print(f"[âœ“] Scaler loaded")

# Test directory
test_dir = os.path.expanduser('~/malware_detection/Test/VMShare')

# Get feature columns from training data
csv_path = os.path.expanduser('~/malware_detection/dataset/data_with_features.csv')
df_train = pd.read_csv(csv_path, nrows=1)
exclude_cols = ['protocol', 'remote_ip', 'local_ip', 'md5_hash', 'sha512_hash', 'data_hex', 'class', 'target']
feature_cols = [col for col in df_train.columns if col not in exclude_cols and col not in ['target']]

print(f"\n[*] Features used: {len(feature_cols)}")
print(f"[*] Feature columns: {feature_cols[:5]}...")

# Get all test files
test_files = sorted([f for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))])
print(f"\n[*] Found {len(test_files)} test files in {test_dir}")

print(f"\n{'='*100}")
print(f"{'File Name':<40} {'Result':<15} {'Malware Prob':<15} {'Benign Prob':<15}")
print(f"{'='*100}")

results = []
malware_count = 0
benign_count = 0

for filename in test_files:
    filepath = os.path.join(test_dir, filename)
    
    try:
        # Read binary file
        with open(filepath, 'rb') as f:
            binary_data = f.read()
        
        # Extract simple features from binary
        file_size = len(binary_data)
        
        # Compute hashes
        md5_hash = hashlib.md5(binary_data).hexdigest()
        sha512_hash = hashlib.sha512(binary_data).hexdigest()
        
        # Entropy calculation
        if len(binary_data) > 0:
            entropy = 0
            for i in range(256):
                p = binary_data.count(i) / len(binary_data)
                if p > 0:
                    entropy -= p * np.log2(p)
        else:
            entropy = 0
        
        # Create feature vector with same structure as training data
        # Initialize with zeros
        feature_vector = np.zeros(len(feature_cols))
        
        # Try to match with existing data or use computed features
        # For now, we'll use basic file characteristics
        if 'length' in feature_cols:
            feature_vector[feature_cols.index('length')] = file_size
        if 'hex_entropy' in feature_cols:
            feature_vector[feature_cols.index('hex_entropy')] = entropy
        if 'length_log' in feature_cols and file_size > 0:
            feature_vector[feature_cols.index('length_log')] = np.log(file_size)
        if 'length_log2' in feature_cols and file_size > 0:
            feature_vector[feature_cols.index('length_log2')] = np.log2(file_size)
        if 'length_sqrt' in feature_cols and file_size > 0:
            feature_vector[feature_cols.index('length_sqrt')] = np.sqrt(file_size)
        if 'length_squared' in feature_cols:
            feature_vector[feature_cols.index('length_squared')] = file_size ** 2
        
        # Scale the feature vector
        feature_vector = feature_vector.reshape(1, -1)
        feature_scaled = scaler.transform(feature_vector)
        
        # Make prediction
        prediction = model.predict(feature_scaled)[0]
        probability = model.predict_proba(feature_scaled)[0]
        
        result = "ðŸ”´ MALWARE" if prediction == 1 else "ðŸŸ¢ BENIGN"
        malware_prob = probability[1]
        benign_prob = probability[0]
        
        if prediction == 1:
            malware_count += 1
        else:
            benign_count += 1
        
        print(f"{filename:<40} {result:<15} {malware_prob:<15.4f} {benign_prob:<15.4f}")
        
        results.append({
            'filename': filename,
            'md5': md5_hash,
            'file_size': file_size,
            'entropy': entropy,
            'prediction': result,
            'malware_prob': malware_prob,
            'benign_prob': benign_prob
        })
        
    except Exception as e:
        print(f"{filename:<40} {'[ERROR]':<15} {str(e):<30}")

print(f"\n{'='*100}")
print(f"\n[*] Tá»”NG Káº¾T:")
print(f"  - PhÃ¡t hiá»‡n Malware: {malware_count}")
print(f"  - PhÃ¡t hiá»‡n Benign: {benign_count}")
print(f"  - Tá»•ng: {len(test_files)}")

print(f"\n[âœ“] Testing completed!")
